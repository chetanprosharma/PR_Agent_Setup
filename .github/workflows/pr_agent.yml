name: PR Agent (Ollama CPU)

on:
  pull_request:
    types: [opened, reopened, ready_for_review]
  issue_comment:
    types: [created]

jobs:
  pr_agent_job:
    # Do not react to bot comments
    if: ${{ github.event.sender.type != 'Bot' }}

    # REQUIRED: self-hosted runner (WSL/Linux)
    runs-on: self-hosted

    permissions:
      issues: write
      pull-requests: write
      contents: write

    env:
      # Ollama endpoint (Docker or local Ollama)
      OLLAMA_BASE_URL: "http://host.docker.internal:11434"
      OLLAMA_HOST: "http://host.docker.internal:11434"

      # LiteLLM stability (CPU-safe)
      PR_AGENT_LLM_PROVIDER: "litellm"
      LITELLM_REQUEST_TIMEOUT: "600"
      LITELLM_TIMEOUT: "600"
      LITELLM_MAX_RETRIES: "2"

      # CPU tuning
      PR_AGENT_MAX_TOKENS: "8192"
      PR_AGENT_TEMPERATURE: "0.2"
      PR_AGENT_TOP_P: "0.9"
      PR_AGENT_PARALLEL_REQUESTS: "1"

    steps:
      - name : Test Ollama Connectivity
        run: |
          curl http://host.docker.internal:11434/api/tags
      - name: Run PR Agent
        uses: qodo-ai/pr-agent@main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

          # Primary model (best CPU choice)
          config.model: "ollama/qwen2.5-coder:7b"

          # Automatic fallbacks (fast â†’ slower)
          config.fallback_models: >
            [
              "ollama/codellama:7b",
              "ollama/deepseek-coder:6.7b"
            ]

          config.custom_model_max_tokens: "8192"

          # Enable PR Agent features
          github_action_config.auto_review: "true"
          github_action_config.auto_describe: "true"
          github_action_config.auto_improve: "false"

          # Enable comment commands like /review /describe
          github_action_config.respond_to_comments: "true"

          # Events PR Agent reacts to
          github_action_config.pr_actions: >
            ["opened","reopened","ready_for_review","commented"]
